#!/usr/bin/env python3
"""
Centralized TensorFlow Configuration for M1/M2 Mac Safety

CRITICAL: This module MUST be imported before any TensorFlow usage
to prevent Metal plugin crashes and GPU configuration errors.
"""

import os
import warnings

# **CRITICAL: Set TensorFlow environment variables BEFORE importing**
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reduce TensorFlow logging
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Disable oneDNN optimizations
os.environ['TF_METAL_DEVICE_PLACEMENT'] = '0'  # **DISABLE automatic Metal placement**
os.environ['TF_DISABLE_MKL'] = '1'  # **DISABLE MKL to avoid conflicts**
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = '1'  # **NEW: Force GPU memory growth**
os.environ['CUDA_VISIBLE_DEVICES'] = ''  # **NEW: Disable CUDA to force CPU/Metal only**

# **NEW: Aggressive Metal prevention**
os.environ['TF_DISABLE_SEGMENT_REDUCTION_OP'] = '1'
os.environ['TF_DISABLE_MKL_SMALL_MATRIX_OPT'] = '1'
os.environ['MLX_METAL_DEBUG'] = '0'  # Disable Metal debugging

warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)

def print_system_resources():
    """Print detailed system resource information"""
    import platform
    import psutil
    
    print("\n" + "="*60)
    print("üñ•Ô∏è  SYSTEM RESOURCE INFORMATION")
    print("="*60)
    
    # System info
    print(f"üíª Platform: {platform.platform()}")
    print(f"üèóÔ∏è  Architecture: {platform.machine()}")
    print(f"üß† CPU Cores: {psutil.cpu_count(logical=False)} physical, {psutil.cpu_count(logical=True)} logical")
    
    # Memory info
    memory = psutil.virtual_memory()
    print(f"üíæ RAM: {memory.total / (1024**3):.1f} GB total, {memory.available / (1024**3):.1f} GB available")
    
    # Detect M1/M2 Mac
    if platform.machine() == 'arm64' and platform.system() == 'Darwin':
        print("üçé Apple Silicon (M1/M2) detected - optimized for ARM64")
    elif platform.machine() == 'x86_64':
        print("üñ•Ô∏è  Intel/AMD x86_64 architecture detected")
    
    print("="*60)

def print_tensorflow_device_info():
    """Print TensorFlow device configuration and availability"""
    try:
        import tensorflow as tf
        
        print("\n" + "="*60)
        print("üîß TENSORFLOW DEVICE CONFIGURATION")
        print("="*60)
        
        # TensorFlow version
        print(f"üì¶ TensorFlow Version: {tf.__version__}")
        
        # Check physical devices
        print("\nüì± Physical Devices:")
        try:
            physical_devices = tf.config.list_physical_devices()
            if physical_devices:
                for device in physical_devices:
                    print(f"   ‚úÖ {device}")
            else:
                print("   ‚ö†Ô∏è  No physical devices detected")
        except Exception as e:
            print(f"   ‚ùå Error getting physical devices: {e}")
        
        # Check GPU availability
        print("\nüéÆ GPU Status:")
        try:
            gpus = tf.config.list_physical_devices('GPU')
            if gpus:
                print(f"   ‚úÖ {len(gpus)} GPU(s) detected:")
                for i, gpu in enumerate(gpus):
                    print(f"      GPU {i}: {gpu}")
                    
                # Check if GPUs are actually usable
                try:
                    tf.config.experimental.set_memory_growth(gpus[0], True)
                    print("   ‚úÖ GPU memory growth enabled")
                except Exception as gpu_config_error:
                    print(f"   ‚ö†Ô∏è  GPU configuration warning: {gpu_config_error}")
            else:
                print("   ‚ùå No GPUs detected or GPU access disabled")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  GPU check error: {e}")
        
        # Check current strategy
        print("\nüéØ Training Strategy:")
        try:
            strategy = tf.distribute.get_strategy()
            print(f"   üìä Strategy: {type(strategy).__name__}")
            print(f"   üî¢ Number of replicas: {strategy.num_replicas_in_sync}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Strategy error: {e}")
        
        # Check mixed precision
        print("\n‚ö° Performance Options:")
        try:
            policy = tf.keras.mixed_precision.global_policy()
            print(f"   üé≠ Mixed Precision Policy: {policy.name}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Mixed precision check error: {e}")
        
        print("="*60)
        
    except ImportError:
        print("\n‚ùå TensorFlow not available for device info")
    except Exception as e:
        print(f"\n‚ùå Error getting TensorFlow device info: {e}")

def get_current_device():
    """Get the current TensorFlow device being used"""
    try:
        import tensorflow as tf
        
        # Try to determine current device
        try:
            # Create a simple operation to see where it runs
            with tf.device(None):  # Let TF choose
                test_op = tf.constant([1.0])
                device_name = test_op.device
                
            if device_name:
                if 'GPU' in device_name:
                    return f"üéÆ GPU: {device_name}"
                elif 'CPU' in device_name:
                    return f"üñ•Ô∏è  CPU: {device_name}"
                else:
                    return f"ü§î Unknown: {device_name}"
            else:
                return "ü§∑ Device not specified"
                
        except Exception as device_error:
            # Fallback: check available devices
            try:
                gpus = tf.config.list_physical_devices('GPU')
                if gpus and len(gpus) > 0:
                    return f"üéÆ GPU Available: {len(gpus)} device(s)"
                else:
                    return "üñ•Ô∏è  CPU (No GPU available)"
            except:
                return "üñ•Ô∏è  CPU (Fallback mode)"
                
    except ImportError:
        return "‚ùå TensorFlow not available"
    except Exception as e:
        return f"‚ùå Device detection error: {e}"

def print_training_device_info():
    """Print comprehensive device info before training starts"""
    print("\n" + "üöÄ" + "="*58 + "üöÄ")
    print("üéØ TRAINING RESOURCE ALLOCATION")
    print("üöÄ" + "="*58 + "üöÄ")
    
    # System resources
    print_system_resources()
    
    # TensorFlow devices
    print_tensorflow_device_info()
    
    # Current device being used
    current_device = get_current_device()
    print(f"\nüéØ CURRENT TRAINING DEVICE: {current_device}")
    
    print("\n" + "üöÄ" + "="*58 + "üöÄ")

def monitor_training_resources():
    """Monitor resource usage during training"""
    import psutil
    
    try:
        # CPU usage
        cpu_percent = psutil.cpu_percent(interval=1)
        
        # Memory usage
        memory = psutil.virtual_memory()
        memory_percent = memory.percent
        memory_used_gb = (memory.total - memory.available) / (1024**3)
        memory_total_gb = memory.total / (1024**3)
        
        # TensorFlow device
        current_device = get_current_device()
        
        print(f"üìä Resource Usage: CPU {cpu_percent:.1f}% | "
              f"RAM {memory_used_gb:.1f}/{memory_total_gb:.1f} GB ({memory_percent:.1f}%) | "
              f"Device: {current_device.split(': ')[-1] if ': ' in current_device else current_device}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Resource monitoring error: {e}")

def is_tensorflow_available():
    """Check if TensorFlow is available and can be imported safely"""
    try:
        import tensorflow as tf
        # Basic functionality test with CPU enforcement
        with tf.device('/CPU:0'):
            _ = tf.constant([1.0, 2.0, 3.0])
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è TensorFlow not available: {e}")
        return False

def get_tensorflow():
    """Get TensorFlow with ultra-conservative safety configuration"""
    try:
        import tensorflow as tf
        
        print("üîß Configuring TensorFlow for MAXIMUM M1/M2 Mac safety...")
        
        # **CRITICAL: FORCE CPU-ONLY MODE for stability**
        try:
            # Completely disable GPU access to prevent Metal crashes
            tf.config.set_visible_devices([], 'GPU')
            print("‚úÖ GPU access DISABLED - CPU-only mode enforced")
        except Exception as gpu_disable_error:
            print(f"‚ö†Ô∏è GPU disable warning: {gpu_disable_error}")
        
        # **AGGRESSIVE: Set very conservative threading**
        try:
            tf.config.threading.set_inter_op_parallelism_threads(1)
            tf.config.threading.set_intra_op_parallelism_threads(1)  # Single thread only
            print("‚úÖ Ultra-conservative single-threading enabled")
        except Exception as threading_error:
            print(f"‚ö†Ô∏è Threading config warning: {threading_error}")
        
        # **FORCE all operations to CPU**
        try:
            # Set default device to CPU
            tf.config.experimental.set_device_policy('silent_for_int32')
            print("‚úÖ CPU-only device policy set")
        except Exception as device_error:
            print(f"‚ö†Ô∏è Device policy warning: {device_error}")
        
        # **Disable ALL GPU/Metal optimizations**
        try:
            # Disable experimental features that might use Metal
            if hasattr(tf.config, 'experimental'):
                if hasattr(tf.config.experimental, 'enable_mlir_bridge'):
                    tf.config.experimental.enable_mlir_bridge(False)
                    print("‚úÖ MLIR bridge disabled")
                if hasattr(tf.config.experimental, 'enable_mlir_graph_optimization'):
                    tf.config.experimental.enable_mlir_graph_optimization(False)
                    print("‚úÖ MLIR graph optimization disabled")
        except Exception as mlir_error:
            print(f"‚ö†Ô∏è MLIR disable warning: {mlir_error}")
        
        # **Test TensorFlow functionality with STRICT CPU enforcement**
        try:
            with tf.device('/CPU:0'):
                test_result = tf.constant([1., 2., 3.])
                test_computation = tf.reduce_sum(test_result)
                final_result = test_computation.numpy()
                print(f"‚úÖ TensorFlow CPU-only test successful: {final_result}")
        except Exception as test_error:
            print(f"‚ö†Ô∏è TensorFlow test failed: {test_error}")
            print("üîÑ Attempting basic TensorFlow without device specification...")
            try:
                test_basic = tf.constant([1., 2., 3.])
                print(f"‚úÖ Basic TensorFlow test successful: {test_basic.numpy()}")
            except Exception as basic_error:
                print(f"‚ùå Even basic TensorFlow failed: {basic_error}")
                # Still return TF object for compatibility
        
        print("‚úÖ TensorFlow ULTRA-SAFE configuration complete (CPU-ONLY)")
        return tf
        
    except ImportError as e:
        print(f"‚ùå TensorFlow import error: {e}")
        return None
    except Exception as e:
        print(f"‚ùå TensorFlow configuration error: {e}")
        # **CRITICAL: Try to return basic TensorFlow if available**
        try:
            import tensorflow as tf
            print("üîÑ Returning basic TensorFlow without advanced config")
            # Force CPU mode even for basic TF
            try:
                tf.config.set_visible_devices([], 'GPU')
            except:
                pass
            return tf
        except:
            return None

# **GLOBAL: Initialize TensorFlow on import (if available)**
TF_AVAILABLE = is_tensorflow_available()
if TF_AVAILABLE:
    tf = get_tensorflow()
else:
    tf = None
    print("‚ö†Ô∏è TensorFlow not available - using CPU fallback mode") 