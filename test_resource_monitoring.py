#!/usr/bin/env python3
"""
Resource Monitoring Test Script

Bu script eÄŸitim sÄ±rasÄ±nda hangi resource'un (GPU/CPU) kullanÄ±ldÄ±ÄŸÄ±nÄ± test eder.
"""

print("ğŸ”§ Resource Monitoring Test baÅŸlÄ±yor...")

# TensorFlow configuration import (FIRST!)
from tf_config import print_training_device_info, monitor_training_resources, get_current_device

print("\nğŸ¯ Sistem resource bilgileri:")
print_training_device_info()

# Test data oluÅŸtur
import numpy as np
import pandas as pd
from datetime import datetime, timedelta

print("\nğŸ“Š Test verisi oluÅŸturuluyor...")

# Synthetic crypto data
dates = pd.date_range(start='2023-01-01', end='2024-01-01', freq='4H')
np.random.seed(42)

data = {
    'open': np.random.uniform(40000, 45000, len(dates)),
    'high': np.random.uniform(45000, 50000, len(dates)),
    'low': np.random.uniform(35000, 40000, len(dates)),
    'close': np.random.uniform(40000, 45000, len(dates)),
    'volume': np.random.uniform(1000, 5000, len(dates))
}

df = pd.DataFrame(data, index=dates)
print(f"âœ… Test verisi hazÄ±r: {len(df)} data points")

# Test 1: LSTM Model Resource Monitoring
print("\n" + "="*60)
print("ğŸ§  LSTM MODEL RESOURCE TEST")
print("="*60)

try:
    from lstm_model import CryptoLSTMModel
    from data_preprocessor import CryptoDataPreprocessor
    
    # Data preprocessing
    preprocessor = CryptoDataPreprocessor()
    processed_df = preprocessor.prepare_data(df, use_technical_indicators=True)
    
    if processed_df is not None:
        scaled_data = preprocessor.scale_data(processed_df, fit_scaler=True)
        X, y = preprocessor.create_sequences(scaled_data, sequence_length=30)  # Smaller sequence for test
        
        # Split data
        split_idx = int(len(X) * 0.8)
        X_train, X_val = X[:split_idx], X[split_idx:]
        y_train, y_val = y[:split_idx], y[split_idx:]
        
        # Create and train LSTM model
        lstm_model = CryptoLSTMModel(sequence_length=30, n_features=X.shape[2])
        lstm_model.build_model([32, 32], dropout_rate=0.2, learning_rate=0.001)
        
        print(f"ğŸ¯ LSTM eÄŸitimi baÅŸlÄ±yor...")
        print(f"ğŸ“Š Training device: {get_current_device()}")
        
        # Train with resource monitoring
        history = lstm_model.train_model(
            X_train, y_train, X_val, y_val,
            epochs=5,  # KÄ±sa test iÃ§in 5 epoch
            batch_size=16,
            verbose=True
        )
        
        if history:
            print("âœ… LSTM test tamamlandÄ±!")
        else:
            print("âŒ LSTM test baÅŸarÄ±sÄ±z")
    else:
        print("âŒ Data preprocessing baÅŸarÄ±sÄ±z")
        
except Exception as lstm_error:
    print(f"âŒ LSTM test hatasÄ±: {lstm_error}")

# Test 2: DQN Model Resource Monitoring
print("\n" + "="*60)
print("ğŸ¤– DQN MODEL RESOURCE TEST")
print("="*60)

try:
    from dqn_trading_model import DQNTradingModel
    
    # Create DQN model
    dqn_model = DQNTradingModel(lookback_window=30, initial_balance=10000)
    
    if processed_df is not None:
        dqn_model.prepare_data(processed_df)
        
        print(f"ğŸ¯ DQN eÄŸitimi baÅŸlÄ±yor...")
        print(f"ğŸ“Š Training device: {get_current_device()}")
        
        # Train with resource monitoring
        training_results = dqn_model.train(
            processed_df,
            episodes=20,  # KÄ±sa test iÃ§in 20 episode
            verbose=True
        )
        
        if training_results:
            print("âœ… DQN test tamamlandÄ±!")
        else:
            print("âŒ DQN test baÅŸarÄ±sÄ±z")
    else:
        print("âŒ Data preprocessing baÅŸarÄ±sÄ±z - DQN test atlanÄ±yor")
        
except Exception as dqn_error:
    print(f"âŒ DQN test hatasÄ±: {dqn_error}")

# Test 3: Hybrid Model Resource Monitoring  
print("\n" + "="*60)
print("ğŸ”¥ HYBRID MODEL RESOURCE TEST")
print("="*60)

try:
    from hybrid_trading_model import HybridTradingModel
    
    # Create hybrid model
    hybrid_model = HybridTradingModel(sequence_length=30, initial_balance=10000)
    
    if processed_df is not None:
        print(f"ğŸ¯ Hybrid eÄŸitimi baÅŸlÄ±yor...")
        print(f"ğŸ“Š Training device: {get_current_device()}")
        
        # Train with comprehensive resource monitoring
        success = hybrid_model.train_hybrid_model(
            processed_df,
            lstm_epochs=3,   # Ã‡ok kÄ±sa test iÃ§in
            dqn_episodes=10, # Ã‡ok kÄ±sa test iÃ§in  
            verbose=True
        )
        
        if success:
            print("âœ… Hybrid test tamamlandÄ±!")
            
            # Test prediction to verify model works
            prediction = hybrid_model.predict_hybrid_action(processed_df.tail(60))
            if prediction['success']:
                print(f"ğŸ¯ Test prediction confidence: {prediction['confidence']:.1%}")
            else:
                print("âš ï¸ Test prediction baÅŸarÄ±sÄ±z")
        else:
            print("âŒ Hybrid test baÅŸarÄ±sÄ±z")
    else:
        print("âŒ Data preprocessing baÅŸarÄ±sÄ±z - Hybrid test atlanÄ±yor")
        
except Exception as hybrid_error:
    print(f"âŒ Hybrid test hatasÄ±: {hybrid_error}")

# Final Summary
print("\n" + "ğŸ¯" + "="*58 + "ğŸ¯")
print("ğŸ RESOURCE MONITORING TEST SUMMARY")
print("ğŸ¯" + "="*58 + "ğŸ¯")

print("\nğŸ“Š Final Resource State:")
monitor_training_resources()

final_device = get_current_device()
print(f"\nğŸ¯ All tests completed on: {final_device}")

print(f"\nğŸ’¡ Resource Monitoring Features:")
print(f"   âœ… System information detection")
print(f"   âœ… TensorFlow device configuration")
print(f"   âœ… Real-time CPU/RAM monitoring")
print(f"   âœ… Training device identification")
print(f"   âœ… Pre/post training resource tracking")

print(f"\nğŸ¯ Usage in your training:")
print(f"   â€¢ LSTM: Kullan 'verbose=True' parametresini")
print(f"   â€¢ DQN: Kullan 'verbose=True' parametresini") 
print(f"   â€¢ Hybrid: Kullan 'verbose=True' parametresini")
print(f"   â€¢ Manuel: 'from tf_config import monitor_training_resources'")

print("\nğŸ¯" + "="*58 + "ğŸ¯")
print("âœ… Resource monitoring test tamamlandÄ±!") 